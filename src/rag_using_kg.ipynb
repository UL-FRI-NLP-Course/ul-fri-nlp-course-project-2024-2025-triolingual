{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3185bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import warnings\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import requests\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74a33831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 5 QA items\n"
     ]
    }
   ],
   "source": [
    "with open(\"../world_leaders_qa_dataset.json\", \"r\") as f:\n",
    "    kg_data = json.load(f)\n",
    "\n",
    "print(f\"loaded {len(kg_data)} QA items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f6b7ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 5 documents.\n"
     ]
    }
   ],
   "source": [
    "def get_wikidata_labels(qids, language='en'):\n",
    "\n",
    "    url = 'https://www.wikidata.org/w/api.php'\n",
    "    labels = {}\n",
    "    batch_size = 50  # Max per API call\n",
    "\n",
    "    for i in range(0, len(qids), batch_size):\n",
    "        batch = qids[i:i+batch_size]\n",
    "        params = {\n",
    "            'action': 'wbgetentities',\n",
    "            'ids': '|'.join(batch),\n",
    "            'format': 'json',\n",
    "            'props': 'labels',\n",
    "            'languages': language\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        for qid in batch:\n",
    "            label = data[\"entities\"][qid][\"labels\"].get(language, {}).get(\"value\")\n",
    "            labels[qid] = label if label else qid\n",
    "    return labels\n",
    "\n",
    "def extract_statements(item, map_qids=True, language='en'):\n",
    "\n",
    "    statements = []\n",
    "    qids = set()\n",
    "\n",
    "    for triple in item.get(\"triples\", []):\n",
    "        subj, _, _, rel, obj = triple\n",
    "        if map_qids:\n",
    "            if subj.startswith(\"Q\"):\n",
    "                qids.add(subj)\n",
    "            if obj.startswith(\"Q\"):\n",
    "                qids.add(obj)\n",
    "\n",
    "    id_to_label = get_wikidata_labels(list(qids), language) if map_qids else {}\n",
    "\n",
    "    for triple in item.get(\"triples\", []):\n",
    "        subj, _, _, rel, obj = triple\n",
    "        subj_label = id_to_label.get(subj, subj)\n",
    "        obj_label = id_to_label.get(obj, obj)\n",
    "        statements.append(f\"{subj_label} {rel} {obj_label}.\")\n",
    "\n",
    "    if \"context_hint\" in item:\n",
    "        statements.append(f\"Hint: {item['context_hint']}\")\n",
    "\n",
    "    return \"\\n\".join(statements)\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=extract_statements(item),\n",
    "        metadata={\"question\": item.get(\"question\", \"\"), \"answer\": item.get(\"answer\", \"\")}\n",
    "    )\n",
    "    for item in kg_data\n",
    "]\n",
    "print(f\"Prepared {len(documents)} documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3d26060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorstore created\n"
     ]
    }
   ],
   "source": [
    "embedding_model = \"all-MiniLM-L6-v2\" # used for semantic encoding of the question\n",
    "embedder = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "vectorstore = FAISS.from_documents(documents, embedder)\n",
    "\n",
    "print(\"vectorstore created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5beda9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "#models = {\n",
    "#    \"phi\": \"microsoft/phi-1_5\",\n",
    "#    \"deepseek\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "#    \"tinyllama\": \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "#}\n",
    "\n",
    "\n",
    "model_id = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=32,               # short answers \n",
    "    temperature=0.0,                 # deterministic\n",
    "    return_full_text=False\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7deeadb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are given the following knowledge facts:\n",
    "\n",
    "{context}\n",
    "\n",
    "Based on this information, answer the following question concisely.\n",
    "Only answer the current question. Do not continue or generate other questions.\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77f9753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 1}), # use only the first most relevant context\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3d84b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- QUESTION --\n",
      "Who is the head of state of Italy?\n",
      "\n",
      "-- RETRIEVED CONTEXTS --\n",
      "\n",
      "-- Context --\n",
      "Sergio Mattarella image http://commons.wikimedia.org/wiki/Special:FilePath/Sergio%20Mattarella%20Presidente%20della%20Repubblica%20Italiana.jpg.\n",
      "Sergio Mattarella place of birth Palermo.\n",
      "Sergio Mattarella sex or gender male.\n",
      "Sergio Mattarella father Bernardo Mattarella.\n",
      "Sergio Mattarella mother Maria Buccellato.\n",
      "Sergio Mattarella spouse Marisa Chiazzese.\n",
      "Sergio Mattarella country of citizenship Italy.\n",
      "Sergio Mattarella instance of human.\n",
      "Sergio Mattarella position held President of Italy.\n",
      "Sergio Mattarella child Bernardo Giorgio Mattarella.\n",
      "Sergio Mattarella child Laura Mattarella.\n",
      "Sergio Mattarella educated at Sapienza University of Rome.\n",
      "Sergio Mattarella educated at University of Palermo.\n",
      "Sergio Mattarella field of work politics.\n",
      "Sergio Mattarella field of work law.\n",
      "Sergio Mattarella me\n",
      "\n",
      "-- MODEL ANSWER --\n",
      "Sergio Mattarella, as he is the head of state in Italy.\n",
      "\n",
      "-- GROUND TRUTH --\n",
      "Sergio Mattarella\n"
     ]
    }
   ],
   "source": [
    "# example input\n",
    "query = \"Who is the head of state of Italy?\"\n",
    "ground_truth = \"Sergio Mattarella\"\n",
    "\n",
    "result = qa_chain({\"query\": query})\n",
    "raw_answer = result[\"result\"].strip()\n",
    "short_answer = raw_answer.split(\"\\n\")[0] \n",
    "\n",
    "print(\"-- QUESTION --\")\n",
    "print(query)\n",
    "\n",
    "print(\"\\n-- RETRIEVED CONTEXTS --\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\n-- Context --\")\n",
    "    print(doc.page_content.strip()[:800])  \n",
    "\n",
    "print(\"\\n-- MODEL ANSWER --\")\n",
    "print(short_answer)\n",
    "\n",
    "print(\"\\n-- GROUND TRUTH --\")\n",
    "print(ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7becd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- QUESTION --\n",
      "Who is the head of state of Italy?\n",
      "\n",
      "-- RETRIEVED CONTEXTS --\n",
      "\n",
      "-- Context --\n",
      "Q3956186 image http://commons.wikimedia.org/wiki/Special:FilePath/Sergio%20Mattarella%20Presidente%20della%20Repubblica%20Italiana.jpg.\n",
      "Q3956186 place of birth Palermo.\n",
      "Q3956186 sex or gender male.\n",
      "Q3956186 father Bernardo Mattarella.\n",
      "Q3956186 mother Maria Buccellato.\n",
      "Q3956186 spouse Marisa Chiazzese.\n",
      "Q3956186 country of citizenship Italy.\n",
      "Q3956186 instance of human.\n",
      "Q3956186 position held President of Italy.\n",
      "Q3956186 child Bernardo Giorgio Mattarella.\n",
      "Q3956186 child Laura Mattarella.\n",
      "Q3956186 educated at Sapienza University of Rome.\n",
      "Q3956186 educated at University of Palermo.\n",
      "Q3956186 field of work politics.\n",
      "Q3956186 field of work law.\n",
      "Q3956186 member of political party Democratic Party.\n",
      "Q3956186 native language Italian.\n",
      "Q3956186 occupation judge.\n",
      "Q3956186 occupation lawyer.\n",
      "Q3956186 occu\n",
      "\n",
      "-- MODEL ANSWER --\n",
      "Bernardo Mattarella, as he is the head of state of Italy.\n",
      "\n",
      "-- GROUND TRUTH --\n",
      "Sergio Mattarella\n"
     ]
    }
   ],
   "source": [
    "# example input, context encoded, wrong answer\n",
    "query = \"Who is the head of state of Italy?\"\n",
    "ground_truth = \"Sergio Mattarella\"\n",
    "\n",
    "result = qa_chain({\"query\": query})\n",
    "raw_answer = result[\"result\"].strip()\n",
    "short_answer = raw_answer.split(\"\\n\")[0] \n",
    "\n",
    "print(\"-- QUESTION --\")\n",
    "print(query)\n",
    "\n",
    "print(\"\\n-- RETRIEVED CONTEXTS --\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\n-- Context --\")\n",
    "    print(doc.page_content.strip()[:800])  \n",
    "\n",
    "print(\"\\n-- MODEL ANSWER --\")\n",
    "print(short_answer)\n",
    "\n",
    "print(\"\\n-- GROUND TRUTH --\")\n",
    "print(ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a9cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- QUESTION --\n",
      "Who is the head of state of Italy?\n",
      "\n",
      "-- MODEL RESPONSE WITHOUT CONTEXT --\n",
      "SELECT Head_of_State FROM table WHERE Country = 'Italy';\n",
      "\n",
      "-- Answer: The head of state of Italy is Carlo\n"
     ]
    }
   ],
   "source": [
    "raw_query = \"Who is the head of state of Italy?\"\n",
    "\n",
    "direct_response = llm(raw_query)\n",
    "\n",
    "print(\"-- QUESTION --\")\n",
    "print(raw_query)\n",
    "\n",
    "print(\"\\n-- MODEL RESPONSE WITHOUT CONTEXT --\")\n",
    "print(direct_response.strip())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kg_rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
