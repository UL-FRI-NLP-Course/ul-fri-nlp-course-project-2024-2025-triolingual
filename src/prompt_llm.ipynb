{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01847c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Biljana\\anaconda3\\envs\\rag_llm_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import warnings\n",
    "import re\n",
    "import requests\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3aae21",
   "metadata": {},
   "source": [
    "### Extract the graphs in human readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8f871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../world_leaders_qa_dataset.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21bafe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P31', 'P21', 'P735', 'P27', 'P106']\n"
     ]
    }
   ],
   "source": [
    "def extract_all_property_ids_from_dataset(dataset):\n",
    "    property_ids = set()\n",
    "    for item in dataset:\n",
    "        question = item.get(\"question\", \"\")\n",
    "        matches = re.findall(r'http://www\\.wikidata\\.org/prop/direct/(p\\d+)', question, flags=re.IGNORECASE)\n",
    "        for match in matches:\n",
    "            property_ids.add(match.upper())\n",
    "        graph = item.get(\"graph\", {})\n",
    "        edges = graph.get(\"edges\", [])\n",
    "        for edge in edges:\n",
    "            rel_id = edge.get(\"relation_id\", \"\")\n",
    "            if rel_id.startswith(\"P\"):\n",
    "                property_ids.add(rel_id.upper())\n",
    "    return list(property_ids)\n",
    "\n",
    "print(extract_all_property_ids_from_dataset(data)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e62634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q18921193', 'Q3956186', 'Q2354258', 'Q102257613', 'Q16865067']\n"
     ]
    }
   ],
   "source": [
    "def extract_all_entity_ids_from_dataset(dataset):\n",
    "    entity_ids = set()\n",
    "    for item in dataset:\n",
    "        graph = item.get(\"graph\", {})\n",
    "        nodes = graph.get(\"nodes\", [])\n",
    "        edges = graph.get(\"edges\", [])\n",
    "        for node in nodes:\n",
    "            entity_ids.add(node[\"id\"])\n",
    "        for edge in edges:\n",
    "            entity_ids.add(edge[\"source\"])\n",
    "            entity_ids.add(edge[\"target\"])\n",
    "    return list(entity_ids)\n",
    "\n",
    "print(extract_all_entity_ids_from_dataset(data)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dedb457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_ids = extract_all_property_ids_from_dataset(data)\n",
    "entity_ids = extract_all_entity_ids_from_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e097f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human readable labels from wikidata id labels\n",
    "def get_property_label(property_id):\n",
    "    url = f\"https://www.wikidata.org/wiki/Special:EntityData/{property_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return property_id\n",
    "    try:\n",
    "        data = response.json()\n",
    "        return data[\"entities\"][property_id][\"labels\"][\"en\"][\"value\"]\n",
    "    except:\n",
    "        return property_id\n",
    "\n",
    "def get_entity_label(entity_id):\n",
    "    url = f\"https://www.wikidata.org/wiki/Special:EntityData/{entity_id}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return entity_id\n",
    "    try:\n",
    "        data = response.json()\n",
    "        return data[\"entities\"][entity_id][\"labels\"][\"en\"][\"value\"]\n",
    "    except:\n",
    "        return entity_id\n",
    "    \n",
    "def build_entity_labels_from_graph(dataset):\n",
    "    labels = {}\n",
    "    for item in dataset:\n",
    "        for node in item.get(\"graph\", {}).get(\"nodes\", []):\n",
    "            node_id = node[\"id\"]\n",
    "            label = node[\"label\"]\n",
    "\n",
    "            if isinstance(label, str):\n",
    "                labels[node_id] = label\n",
    "            elif isinstance(label, dict):\n",
    "                name_like_keys = [\"Commons category\", \"en\", \"name\", \"label\"]\n",
    "                found = None\n",
    "                for key in name_like_keys:\n",
    "                    if key in label:\n",
    "                        found = label[key]\n",
    "                        break\n",
    "                if found:\n",
    "                    labels[node_id] = found\n",
    "                else:\n",
    "                    labels[node_id] = node_id  \n",
    "            else:\n",
    "                labels[node_id] = node_id  \n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "PROPERTY_LABELS = {pid: get_property_label(pid) for pid in property_ids}\n",
    "ENTITY_LABELS = {eid: get_entity_label(eid) for eid in entity_ids}\n",
    "# build_entity_labels_from_graph(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba472542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_question(question):\n",
    "    question = re.sub(\n",
    "        r'http://www\\.wikidata\\.org/prop/direct/(p\\d+)',lambda m: m.group(1).upper(),question,flags=re.IGNORECASE)\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f5fc0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(question, property_labels):\n",
    "    question = clean_question(question)\n",
    "    for prop_id, label in property_labels.items():\n",
    "        question = question.replace(prop_id, label)\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a98a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_by_id(entity_id, nodes=None):\n",
    "    return ENTITY_LABELS.get(entity_id, entity_id)\n",
    "\n",
    "def extract_humanized_facts(graph, focus_entity=None, property_labels=None):\n",
    "    edges = graph.get(\"edges\", [])\n",
    "    facts = []\n",
    "    for edge in edges:\n",
    "        if focus_entity and edge[\"source\"] != focus_entity:\n",
    "            continue\n",
    "        source_label = get_label_by_id(edge[\"source\"])\n",
    "        target_label = get_label_by_id(edge[\"target\"])\n",
    "        relation_id = edge.get(\"relation_id\", \"\")\n",
    "        relation = property_labels.get(relation_id, edge.get(\"relation\", relation_id))\n",
    "        facts.append(f\"{source_label} {relation} {target_label}\")\n",
    "    return facts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42781efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_with_context(question, facts, property_labels):\n",
    "    cleaned_question = process_question(question, property_labels)\n",
    "    context = \"\\n\".join(facts)\n",
    "    return f\"Context:\\n{context}\\n\\nQuestion: {cleaned_question}\\nAnswer:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d84d46ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "Donald Trump relative John G. Trump\n",
      "Donald Trump relative Vanessa Trump\n",
      "Donald Trump relative Jared Kushner\n",
      "Donald Trump relative Donald Trump III\n",
      "Donald Trump relative Elizabeth Christ Trump\n",
      "Donald Trump relative Lara Trump\n",
      "Donald Trump relative Mary L. Trump\n",
      "Donald Trump relative John Whitney Walter\n",
      "Donald Trump medical condition COVID-19\n",
      "Donald Trump topic's main Wikimedia portal Portal:Donald J. Trump\n",
      "\n",
      "Question: Which person serves as the head of state of United States?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# exmaple question + context \n",
    "sample = data[4]  \n",
    "\n",
    "leader_id = sample.get(\"leader_id\")  \n",
    "facts = extract_humanized_facts(sample[\"graph\"], focus_entity=leader_id, property_labels=PROPERTY_LABELS)\n",
    "\n",
    "prompt = build_prompt_with_context(sample[\"question\"], facts, PROPERTY_LABELS)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "251cc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        ),\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81e337d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(prompt, model, tokenizer, max_tokens=40):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_tokens,\n",
    "        do_sample=False,\n",
    "        temperature=0.0,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"Answer:\" in output:\n",
    "        return output.split(\"Answer:\")[1].split(\"\\n\")[0].strip()\n",
    "    else:\n",
    "        return output.strip().split(\"\\n\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a432e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"phi\": \"microsoft/phi-1_5\",\n",
    "    \"deepseek\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"tinyllama\": \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "}\n",
    "\n",
    "loaded = {name: load_llm(path) for name, path in models.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "596ab07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "Context:\n",
      "Donald Trump relative John G. Trump\n",
      "Donald Trump relative Vanessa Trump\n",
      "Donald Trump relative Jared Kushner\n",
      "Donald Trump relative Donald Trump III\n",
      "Donald Trump relative Elizabeth Christ Trump\n",
      "Donald Trump relative Lara Trump\n",
      "Donald Trump relative Mary L. Trump\n",
      "Donald Trump relative John Whitney Walter\n",
      "Donald Trump medical condition COVID-19\n",
      "Donald Trump topic's main Wikimedia portal Portal:Donald J. Trump\n",
      "\n",
      "Question: Which person serves as the head of state of United States?\n",
      "Answer:\n",
      "\n",
      "--- Model Answers ---\n",
      "[phi] Answer: Donald Trump\n",
      "[deepseek] Answer: John F. Kennedy\n",
      "[tinyllama] Answer: Donald Trump\n",
      "\n",
      "Ground truth: Donald Trump\n"
     ]
    }
   ],
   "source": [
    "sample = data[4]\n",
    "leader_id = sample.get(\"leader_id\")\n",
    "facts = extract_humanized_facts(sample[\"graph\"], focus_entity=leader_id, property_labels=PROPERTY_LABELS)\n",
    "prompt = build_prompt_with_context(sample[\"question\"], facts, PROPERTY_LABELS)\n",
    "\n",
    "print(\"Prompt:\\n\" + prompt)\n",
    "print(\"\\n--- Model Answers ---\")\n",
    "\n",
    "for i, (name, (model, tokenizer)) in enumerate(loaded.items()):\n",
    "    # print(prompt)\n",
    "    answer = query_llm(prompt, model, tokenizer)\n",
    "    print(f\"[{name}] Answer:\", answer)\n",
    "\n",
    "print(\"\\nGround truth:\", sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "364dcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_with_context_given_instruction(question, facts, property_labels):\n",
    "    cleaned_question = process_question(question, property_labels)\n",
    "    context = \"\\n\".join(facts)\n",
    "    return (\"The context provided contains relevant facts. Answer based on them.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\nQuestion: {cleaned_question}\\nAnswer:\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56b3560b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "The context provided contains relevant facts. Answer based on them.\n",
      "\n",
      "Context:\n",
      "Donald Trump relative John G. Trump\n",
      "Donald Trump relative Vanessa Trump\n",
      "Donald Trump relative Jared Kushner\n",
      "Donald Trump relative Donald Trump III\n",
      "Donald Trump relative Elizabeth Christ Trump\n",
      "Donald Trump relative Lara Trump\n",
      "Donald Trump relative Mary L. Trump\n",
      "Donald Trump relative John Whitney Walter\n",
      "Donald Trump medical condition COVID-19\n",
      "Donald Trump topic's main Wikimedia portal Portal:Donald J. Trump\n",
      "\n",
      "Question: Which person serves as the head of state of United States?\n",
      "Answer:\n",
      "\n",
      "--- Model Answers ---\n",
      "[phi] Answer: Donald Trump\n",
      "[deepseek] Answer: Donald J. Trump\n",
      "[tinyllama] Answer: Donald Trump\n",
      "\n",
      "Ground truth: Donald Trump\n"
     ]
    }
   ],
   "source": [
    "prompt = build_prompt_with_context_given_instruction(sample[\"question\"], facts, PROPERTY_LABELS)\n",
    "print(\"Prompt:\\n\" + prompt)\n",
    "print(\"\\n--- Model Answers ---\")\n",
    "\n",
    "for i, (name, (model, tokenizer)) in enumerate(loaded.items()):\n",
    "    # print(prompt)\n",
    "    answer = query_llm(prompt, model, tokenizer)\n",
    "    print(f\"[{name}] Answer:\", answer)\n",
    "\n",
    "print(\"\\nGround truth:\", sample[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
